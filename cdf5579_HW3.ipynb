{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b11018",
   "metadata": {},
   "source": [
    "## Assignment 3, Carlos Figueroa (cdf5579) Machine Learning, Fall 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719847a8",
   "metadata": {},
   "source": [
    "In this notebook, we will work with the dataset: https://archive.ics.uci.edu/ml/datasets/Spambasein in order to study different methods for Support Vector Classification (SVM). For our SVM model, we will use SKlearn packages, that include SVC (Support Vector Classification) inside of the SVM package. The rationale behind using this model is that it allows us to modify its kernel's and C's in a comfortable manner, while simplifying our efforts to provide a robust classification method. \n",
    "\n",
    "Before we begin, let's remind ourselves that kernel is just the shape that the data might have, and C is the Regularization parameter. The strength of the regularization is inversely proportional to C. So it's a variable that will allow us to add slack into our classification, in order to not fall in the pitfalls mentioned in lecture where the separation of the hyperplane is not straightforward.\n",
    "\n",
    "Now, let's start with some analysis on the data, and cleaning procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bcfa896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install packages\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.ticker as mtick\n",
    "#import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "685dc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataframe\n",
    "df = pd.read_csv(\"spambase.data\", names = range(1,59))\n",
    "\n",
    "#column 58 is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2463b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\n",
      "|\n",
      "| 48 continuous real [0,100] attributes of type word_freq_WORD \n",
      "| = percentage of words in the e-mail that match WORD,\n",
      "| i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
      "| total number of words in e-mail.  A \"word\" in this case is any \n",
      "| string of alphanumeric characters bounded by non-alphanumeric \n",
      "| characters or end-of-string.\n",
      "|\n",
      "| 6 continuous real [0,100] attributes of type char_freq_CHAR\n",
      "| = percentage of characters in the e-mail that match CHAR,\n",
      "| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
      "|\n",
      "| 1 continuous real [1,...] attribute of type capital_run_length_average\n",
      "| = average length of uninterrupted sequences of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
      "| = length of longest uninterrupted sequence of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_total\n",
      "| = sum of length of uninterrupted sequences of capital letters\n",
      "| = total number of capital letters in the e-mail\n",
      "|\n",
      "| 1 nominal {0,1} class attribute of type spam\n",
      "| = denotes whether the e-mail was considered spam (1) or not (0), \n",
      "| i.e. unsolicited commercial e-mail.  \n",
      "|\n",
      "| For more information, see file 'spambase.DOCUMENTATION' at the\n",
      "| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
      "\n",
      "\n",
      "1, 0.    | spam, non-spam classes\n",
      "\n",
      "word_freq_make:         continuous.\n",
      "word_freq_address:      continuous.\n",
      "word_freq_all:          continuous.\n",
      "word_freq_3d:           continuous.\n",
      "word_freq_our:          continuous.\n",
      "word_freq_over:         continuous.\n",
      "word_freq_remove:       continuous.\n",
      "word_freq_internet:     continuous.\n",
      "word_freq_order:        continuous.\n",
      "word_freq_mail:         continuous.\n",
      "word_freq_receive:      continuous.\n",
      "word_freq_will:         continuous.\n",
      "word_freq_people:       continuous.\n",
      "word_freq_report:       continuous.\n",
      "word_freq_addresses:    continuous.\n",
      "word_freq_free:         continuous.\n",
      "word_freq_business:     continuous.\n",
      "word_freq_email:        continuous.\n",
      "word_freq_you:          continuous.\n",
      "word_freq_credit:       continuous.\n",
      "word_freq_your:         continuous.\n",
      "word_freq_font:         continuous.\n",
      "word_freq_000:          continuous.\n",
      "word_freq_money:        continuous.\n",
      "word_freq_hp:           continuous.\n",
      "word_freq_hpl:          continuous.\n",
      "word_freq_george:       continuous.\n",
      "word_freq_650:          continuous.\n",
      "word_freq_lab:          continuous.\n",
      "word_freq_labs:         continuous.\n",
      "word_freq_telnet:       continuous.\n",
      "word_freq_857:          continuous.\n",
      "word_freq_data:         continuous.\n",
      "word_freq_415:          continuous.\n",
      "word_freq_85:           continuous.\n",
      "word_freq_technology:   continuous.\n",
      "word_freq_1999:         continuous.\n",
      "word_freq_parts:        continuous.\n",
      "word_freq_pm:           continuous.\n",
      "word_freq_direct:       continuous.\n",
      "word_freq_cs:           continuous.\n",
      "word_freq_meeting:      continuous.\n",
      "word_freq_original:     continuous.\n",
      "word_freq_project:      continuous.\n",
      "word_freq_re:           continuous.\n",
      "word_freq_edu:          continuous.\n",
      "word_freq_table:        continuous.\n",
      "word_freq_conference:   continuous.\n",
      "char_freq_;:            continuous.\n",
      "char_freq_(:            continuous.\n",
      "char_freq_[:            continuous.\n",
      "char_freq_!:            continuous.\n",
      "char_freq_$:            continuous.\n",
      "char_freq_#:            continuous.\n",
      "capital_run_length_average: continuous.\n",
      "capital_run_length_longest: continuous.\n",
      "capital_run_length_total:   continuous.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"spambase.names\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4577d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets bring those column names\n",
    "df.columns  = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                      \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                      \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                      \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                      \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                      \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                      \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                      \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                      \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "                      \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                      \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \n",
    "                      \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_hash\", \"capital_run_length_average\", \n",
    "                      \"capital_run_length_longest\", \"capital_run_length_total\", \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2a223e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_hash</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0.00               0.64           0.64           0.0   \n",
       "1               0.21               0.28           0.50           0.0   \n",
       "2               0.06               0.00           0.71           0.0   \n",
       "3               0.00               0.00           0.00           0.0   \n",
       "4               0.00               0.00           0.00           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596            0.31               0.00           0.62           0.0   \n",
       "4597            0.00               0.00           0.00           0.0   \n",
       "4598            0.30               0.00           0.30           0.0   \n",
       "4599            0.96               0.00           0.00           0.0   \n",
       "4600            0.00               0.00           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0.32            0.00              0.00                0.00   \n",
       "1              0.14            0.28              0.21                0.07   \n",
       "2              1.23            0.19              0.19                0.12   \n",
       "3              0.63            0.00              0.31                0.63   \n",
       "4              0.63            0.00              0.31                0.63   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596           0.00            0.31              0.00                0.00   \n",
       "4597           0.00            0.00              0.00                0.00   \n",
       "4598           0.00            0.00              0.00                0.00   \n",
       "4599           0.32            0.00              0.00                0.00   \n",
       "4600           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0                0.00            0.00  ...        0.000        0.000   \n",
       "1                0.00            0.94  ...        0.000        0.132   \n",
       "2                0.64            0.25  ...        0.010        0.143   \n",
       "3                0.31            0.63  ...        0.000        0.137   \n",
       "4                0.31            0.63  ...        0.000        0.135   \n",
       "...               ...             ...  ...          ...          ...   \n",
       "4596             0.00            0.00  ...        0.000        0.232   \n",
       "4597             0.00            0.00  ...        0.000        0.000   \n",
       "4598             0.00            0.00  ...        0.102        0.718   \n",
       "4599             0.00            0.00  ...        0.000        0.057   \n",
       "4600             0.00            0.00  ...        0.000        0.000   \n",
       "\n",
       "      char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
       "0             0.0        0.778        0.000           0.000   \n",
       "1             0.0        0.372        0.180           0.048   \n",
       "2             0.0        0.276        0.184           0.010   \n",
       "3             0.0        0.137        0.000           0.000   \n",
       "4             0.0        0.135        0.000           0.000   \n",
       "...           ...          ...          ...             ...   \n",
       "4596          0.0        0.000        0.000           0.000   \n",
       "4597          0.0        0.353        0.000           0.000   \n",
       "4598          0.0        0.000        0.000           0.000   \n",
       "4599          0.0        0.000        0.000           0.000   \n",
       "4600          0.0        0.125        0.000           0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0                          3.756                          61   \n",
       "1                          5.114                         101   \n",
       "2                          9.821                         485   \n",
       "3                          3.537                          40   \n",
       "4                          3.537                          40   \n",
       "...                          ...                         ...   \n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  target  \n",
       "0                          278       1  \n",
       "1                         1028       1  \n",
       "2                         2259       1  \n",
       "3                          191       1  \n",
       "4                          191       1  \n",
       "...                        ...     ...  \n",
       "4596                        88       0  \n",
       "4597                        14       0  \n",
       "4598                       118       0  \n",
       "4599                        78       0  \n",
       "4600                        40       0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now, we visualize the dataset to see if everything is in place\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecd279",
   "metadata": {},
   "source": [
    "Now, there's a couple of ways to start our analysis on this data. But first, we note that most of the data is composed of frequencies which go from 0 to a number not higher than 30, meaning that most of the data is really close to each other, and thus comparable across sections. However, we still have the last three variables that are real continuous numbers with no specific range, and that brings a problem to our analysis. \n",
    "\n",
    "Because Support Vector Machine (SVM) optimization occurs by minimizing the decision vector w, the optimal hyperplane is influenced by the scale of the input features and it's therefore recommended that data be standardized (mean 0, var 1) prior to SVM model training. Thus, if we are only comparing the frequencies, there would be not much need to standarize, but since we have those three variables without bounds, we might need to either:\n",
    "\n",
    "1. Perform the analysis without normalizing, nor deleting the last three columns.\n",
    "\n",
    "2. Run our analysis while excluding the last three variables, so that standarizing is not requiered.\n",
    "\n",
    "2. Standarize all of our values before performing the analysis, so that the optimal hyperplane is not influenced by these variables\n",
    "\n",
    "3. Standarize all of our values before performing the analysis, and delete the three last variables\n",
    "\n",
    "Since this study is computationally strong, we will proceed to apply the last three tecniques.\n",
    "\n",
    "Notwithstanding, there are reasons to believe that the last three variables might not be beneficial to our analysis. Those variables are analyzing the lenght of the emails in terms of the characters, and we suspect that spam emails are not longer nor shorter than normal emails in general, so its just a noisy variable that could be jeopardizing our observation. But so is the case for other variables that might not play a strong role in our study, its just that this one jeopardizes in scale particularly.\n",
    "\n",
    "Moreover, for dataslip, we will use SKlearn model_selection package, train_test_split function. The reasons behind this choice its the convenience to break the data at the preferred ratio easily, and because it splits them randomly everytime we call the function, which allows us to repeat iterations and see consistency (pretty useful for bootstrapping)\n",
    "\n",
    "## First, let's exclude variables, no normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2b0dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Y = df[\"target\"] #just need the target column for Y\n",
    "\n",
    "#three last variables\n",
    "X = df.drop([\"target\", \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\"], axis=1) \n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3) #test size 0.2 is for the 80-20 split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73275106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319333816075308"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets fit the model naively\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88769b",
   "metadata": {},
   "source": [
    "But we will want to know more about the specifics of the model, so we have to find the Train Accuracy and Test Accuracy appart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fb51800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941304347826087 0.9319333816075308\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train) \n",
    "train_accuracy = accuracy_score(Y_train,y_train_pred)\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(X_test) \n",
    "test_accuracy = accuracy_score(Y_test,y_test_pred)\n",
    "\n",
    "print(train_accuracy,test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7a41c",
   "metadata": {},
   "source": [
    "## Now, lets apply different kernel functions, and C's\n",
    "\n",
    "Note that these are the parameters of the SVC function: (*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None) \n",
    "\n",
    "Now, since we must fill a table with each kernel type using 7 different C's, we will create a nested loop to perform this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58a5639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with C: 0.01, kernel: rbf\n",
      "train acc: 0.8288819875776398\n",
      "test acc: 0.8204199855177408\n",
      "-----------------------------\n",
      "model with C: 0.01, kernel: linear\n",
      "train acc: 0.9108695652173913\n",
      "test acc: 0.9058653149891384\n",
      "-----------------------------\n",
      "model with C: 0.01, kernel: poly\n",
      "train acc: 0.643167701863354\n",
      "test acc: 0.6227371469949312\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: rbf\n",
      "train acc: 0.9015527950310559\n",
      "test acc: 0.9029688631426502\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: linear\n",
      "train acc: 0.9273291925465839\n",
      "test acc: 0.9167270094134685\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: poly\n",
      "train acc: 0.8307453416149069\n",
      "test acc: 0.8117306299782766\n",
      "-----------------------------\n",
      "model with C: 1, kernel: rbf\n",
      "train acc: 0.941304347826087\n",
      "test acc: 0.9319333816075308\n",
      "-----------------------------\n",
      "model with C: 1, kernel: linear\n",
      "train acc: 0.9301242236024845\n",
      "test acc: 0.9116582186821144\n",
      "-----------------------------\n",
      "model with C: 1, kernel: poly\n",
      "train acc: 0.8819875776397516\n",
      "test acc: 0.8740043446777698\n",
      "-----------------------------\n",
      "model with C: 10, kernel: rbf\n",
      "train acc: 0.9562111801242236\n",
      "test acc: 0.9362780593772628\n",
      "-----------------------------\n",
      "model with C: 10, kernel: linear\n",
      "train acc: 0.9329192546583851\n",
      "test acc: 0.9094858797972484\n",
      "-----------------------------\n",
      "model with C: 10, kernel: poly\n",
      "train acc: 0.9229813664596274\n",
      "test acc: 0.9087617668356264\n",
      "-----------------------------\n",
      "model with C: 100, kernel: rbf\n",
      "train acc: 0.9770186335403727\n",
      "test acc: 0.9377262853005068\n",
      "-----------------------------\n",
      "model with C: 100, kernel: linear\n",
      "train acc: 0.9338509316770186\n",
      "test acc: 0.9080376538740044\n",
      "-----------------------------\n",
      "model with C: 100, kernel: poly\n",
      "train acc: 0.9537267080745342\n",
      "test acc: 0.9246922519913107\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: rbf\n",
      "train acc: 0.9894409937888199\n",
      "test acc: 0.9297610427226647\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: linear\n",
      "train acc: 0.9332298136645962\n",
      "test acc: 0.9073135409123824\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: poly\n",
      "train acc: 0.9720496894409938\n",
      "test acc: 0.9167270094134685\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: rbf\n",
      "train acc: 0.9959627329192546\n",
      "test acc: 0.9138305575669804\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: linear\n",
      "train acc: 0.9360248447204969\n",
      "test acc: 0.9087617668356264\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: poly\n",
      "train acc: 0.986335403726708\n",
      "test acc: 0.9102099927588704\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#different kernels we have to apply\n",
    "C = [.01, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "#list of kernels\n",
    "kernels = ['rbf','linear', 'poly']\n",
    "\n",
    "#train accuracy with diff kernels\n",
    "linear_train_accuracy = []\n",
    "poly_train_accuracy = []\n",
    "rbf_train_accuracy = []\n",
    "\n",
    "#test accuracy with diff kernels\n",
    "linear_test_accuracy = []\n",
    "poly_test_accuracy = []\n",
    "rbf_test_accuracy = []\n",
    "\n",
    "\n",
    "for c in C:\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        \n",
    "        #first, lets fit the model with the determine C and Kernel\n",
    "        #if kernel is poly, then it needs the degree 2, otherwise it is ignored for other kernels\n",
    "        model = SVC(C=c, kernel=kernel, degree = 2)\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        #we get our predictions\n",
    "        y_train_pred = model.predict(X_train) \n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        #we obtain accuracy between predictions and data (from test and train Y)\n",
    "        train_accuracy = accuracy_score(Y_train, y_train_pred) \n",
    "        test_accuracy = accuracy_score(Y_test, y_test_pred)\n",
    "        \n",
    "        #now we qualify them\n",
    "        if kernel == 'rbf':\n",
    "            rbf_train_accuracy.append(train_accuracy)\n",
    "            rbf_test_accuracy.append(test_accuracy)\n",
    "            \n",
    "        elif kernel == 'linear':\n",
    "            linear_train_accuracy.append(train_accuracy)\n",
    "            linear_test_accuracy.append(test_accuracy)\n",
    "            \n",
    "        else:\n",
    "            poly_train_accuracy.append(train_accuracy)\n",
    "            poly_test_accuracy.append(test_accuracy)\n",
    "            \n",
    "            #now we display our results\n",
    "        print(f\"model with C: {c}, kernel: {kernel}\")\n",
    "        print(\"train acc:\", train_accuracy)\n",
    "        print(\"test acc:\", test_accuracy)\n",
    "        print(\"-----------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "635fe8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame([rbf_train_accuracy, linear_train_accuracy, poly_train_accuracy], columns=C, index=kernels)\n",
    "df_test = pd.DataFrame([rbf_test_accuracy, linear_test_accuracy, poly_test_accuracy], columns=C, index=kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8a3542db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['type'] = 'Train Accuracy'\n",
    "df_test['type'] = 'Test Accuracy'\n",
    "\n",
    "all_dfs = [df_train, df_test]\n",
    "\n",
    "# Give all df's common column names\n",
    "\n",
    "model_without_last3 = pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1fd9d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.701553</td>\n",
       "      <td>0.912112</td>\n",
       "      <td>0.946894</td>\n",
       "      <td>0.965839</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.996273</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.912733</td>\n",
       "      <td>0.924534</td>\n",
       "      <td>0.926708</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.931056</td>\n",
       "      <td>0.931988</td>\n",
       "      <td>0.932298</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.629193</td>\n",
       "      <td>0.724224</td>\n",
       "      <td>0.852795</td>\n",
       "      <td>0.951242</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.991925</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.682114</td>\n",
       "      <td>0.902969</td>\n",
       "      <td>0.918175</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.921072</td>\n",
       "      <td>0.901521</td>\n",
       "      <td>0.881245</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.911658</td>\n",
       "      <td>0.911658</td>\n",
       "      <td>0.918175</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.608979</td>\n",
       "      <td>0.724113</td>\n",
       "      <td>0.843592</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>0.885590</td>\n",
       "      <td>0.876901</td>\n",
       "      <td>0.873280</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.01       0.1       1.0      10.0     100.0    1000.0   10000.0  \\\n",
       "rbf     0.701553  0.912112  0.946894  0.965839  0.986957  0.993789  0.996273   \n",
       "linear  0.912733  0.924534  0.926708  0.929503  0.931056  0.931988  0.932298   \n",
       "poly    0.629193  0.724224  0.852795  0.951242  0.972671  0.986957  0.991925   \n",
       "rbf     0.682114  0.902969  0.918175  0.916003  0.921072  0.901521  0.881245   \n",
       "linear  0.905865  0.911658  0.911658  0.918175  0.916003  0.913831  0.913831   \n",
       "poly    0.608979  0.724113  0.843592  0.913831  0.885590  0.876901  0.873280   \n",
       "\n",
       "                  type  \n",
       "rbf     Train Accuracy  \n",
       "linear  Train Accuracy  \n",
       "poly    Train Accuracy  \n",
       "rbf      Test Accuracy  \n",
       "linear   Test Accuracy  \n",
       "poly     Test Accuracy  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_without_last3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6908eb9",
   "metadata": {},
   "source": [
    "## Now we standarize without deleting the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01670c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets Standarize our variables in order to train the model as best practice.\n",
    "\n",
    "Y_1 = df[\"target\"] #just need the target column for Y\n",
    "\n",
    "#three last variables\n",
    "X_1 = df.drop([\"target\"], axis=1) \n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X_1, Y_1, test_size = 0.3) #test size 0.2 is for the 80-20 split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5802822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standarize the variables\n",
    "scaler = StandardScaler()\n",
    "X_train_1 = scaler.fit_transform(X_train_1)\n",
    "X_test_1 = scaler.fit_transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dbb44e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with C: 0.01, kernel: rbf\n",
      "train acc: 0.7161490683229814\n",
      "test acc: 0.7270094134685011\n",
      "-----------------------------\n",
      "model with C: 0.01, kernel: linear\n",
      "train acc: 0.9180124223602485\n",
      "test acc: 0.9275887038377987\n",
      "-----------------------------\n",
      "model with C: 0.01, kernel: poly\n",
      "train acc: 0.6164596273291926\n",
      "test acc: 0.6459087617668356\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: rbf\n",
      "train acc: 0.9090062111801243\n",
      "test acc: 0.9145546705286025\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: linear\n",
      "train acc: 0.9285714285714286\n",
      "test acc: 0.9304851556842868\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: poly\n",
      "train acc: 0.7251552795031055\n",
      "test acc: 0.7371469949312093\n",
      "-----------------------------\n",
      "model with C: 1, kernel: rbf\n",
      "train acc: 0.94472049689441\n",
      "test acc: 0.9370021723388848\n",
      "-----------------------------\n",
      "model with C: 1, kernel: linear\n",
      "train acc: 0.9304347826086956\n",
      "test acc: 0.9297610427226647\n",
      "-----------------------------\n",
      "model with C: 1, kernel: poly\n",
      "train acc: 0.8459627329192546\n",
      "test acc: 0.8573497465604635\n",
      "-----------------------------\n",
      "model with C: 10, kernel: rbf\n",
      "train acc: 0.965527950310559\n",
      "test acc: 0.9384503982621288\n",
      "-----------------------------\n",
      "model with C: 10, kernel: linear\n",
      "train acc: 0.9313664596273292\n",
      "test acc: 0.9333816075307748\n",
      "-----------------------------\n",
      "model with C: 10, kernel: poly\n",
      "train acc: 0.9496894409937888\n",
      "test acc: 0.9254163649529327\n",
      "-----------------------------\n",
      "model with C: 100, kernel: rbf\n",
      "train acc: 0.9854037267080745\n",
      "test acc: 0.9275887038377987\n",
      "-----------------------------\n",
      "model with C: 100, kernel: linear\n",
      "train acc: 0.9347826086956522\n",
      "test acc: 0.939174511223751\n",
      "-----------------------------\n",
      "model with C: 100, kernel: poly\n",
      "train acc: 0.9704968944099379\n",
      "test acc: 0.9131064446053584\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: rbf\n",
      "train acc: 0.9922360248447205\n",
      "test acc: 0.9188993482983345\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: linear\n",
      "train acc: 0.9326086956521739\n",
      "test acc: 0.9370021723388848\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: poly\n",
      "train acc: 0.9872670807453416\n",
      "test acc: 0.8935553946415641\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: rbf\n",
      "train acc: 0.9953416149068323\n",
      "test acc: 0.9051412020275162\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: linear\n",
      "train acc: 0.9329192546583851\n",
      "test acc: 0.9377262853005068\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: poly\n",
      "train acc: 0.9922360248447205\n",
      "test acc: 0.8870383779869659\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#different kernels we have to apply\n",
    "C = [.01, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "#list of kernels\n",
    "kernels = ['rbf','linear', 'poly']\n",
    "\n",
    "#train accuracy with diff kernels\n",
    "linear_train_accuracy_1 = []\n",
    "poly_train_accuracy_1 = []\n",
    "rbf_train_accuracy_1 = []\n",
    "\n",
    "#test accuracy with diff kernels\n",
    "linear_test_accuracy_1 = []\n",
    "poly_test_accuracy_1 = []\n",
    "rbf_test_accuracy_1 = []\n",
    "\n",
    "\n",
    "for c in C:\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        \n",
    "        #first, lets fit the model with the determine C and Kernel\n",
    "        #if kernel is poly, then it needs the degree 2, otherwise it is ignored for other kernels\n",
    "        model = SVC(C=c, kernel=kernel, degree = 2)\n",
    "        model.fit(X_train_1, Y_train_1)\n",
    "        \n",
    "        #we get our predictions\n",
    "        y_train_pred_1 = model.predict(X_train_1) \n",
    "        y_test_pred_1 = model.predict(X_test_1)\n",
    "        \n",
    "        #we obtain accuracy between predictions and data (from test and train Y)\n",
    "        train_accuracy_1 = accuracy_score(Y_train_1, y_train_pred_1) \n",
    "        test_accuracy_1 = accuracy_score(Y_test_1, y_test_pred_1)\n",
    "        \n",
    "        #now we qualify them\n",
    "        if kernel == 'rbf':\n",
    "            rbf_train_accuracy_1.append(train_accuracy_1)\n",
    "            rbf_test_accuracy_1.append(test_accuracy_1)\n",
    "            \n",
    "        elif kernel == 'linear':\n",
    "            linear_train_accuracy_1.append(train_accuracy_1)\n",
    "            linear_test_accuracy_1.append(test_accuracy_1)\n",
    "            \n",
    "        else:\n",
    "            poly_train_accuracy_1.append(train_accuracy_1)\n",
    "            poly_test_accuracy_1.append(test_accuracy_1)\n",
    "            \n",
    "            #now we display our results\n",
    "        print(f\"model with C: {c}, kernel: {kernel}\")\n",
    "        print(\"train acc:\", train_accuracy_1)\n",
    "        print(\"test acc:\", test_accuracy_1)\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "27bd4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = pd.DataFrame([rbf_train_accuracy_1, linear_train_accuracy_1, poly_train_accuracy_1], columns=C, index=kernels)\n",
    "df_test_1 = pd.DataFrame([rbf_test_accuracy_1, linear_test_accuracy_1, poly_test_accuracy_1], columns=C, index=kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e106522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1['type'] = 'Train Accuracy'\n",
    "df_test_1['type'] = 'Test Accuracy'\n",
    "\n",
    "all_dfs_1 = [df_train_1, df_test_1]\n",
    "\n",
    "# Give all df's common column names\n",
    "\n",
    "model_only_standarized = pd.concat(all_dfs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "97568fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.716149</td>\n",
       "      <td>0.909006</td>\n",
       "      <td>0.944720</td>\n",
       "      <td>0.965528</td>\n",
       "      <td>0.985404</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.918012</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.931366</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.932609</td>\n",
       "      <td>0.932919</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.616460</td>\n",
       "      <td>0.725155</td>\n",
       "      <td>0.845963</td>\n",
       "      <td>0.949689</td>\n",
       "      <td>0.970497</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.727009</td>\n",
       "      <td>0.914555</td>\n",
       "      <td>0.937002</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.918899</td>\n",
       "      <td>0.905141</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.930485</td>\n",
       "      <td>0.929761</td>\n",
       "      <td>0.933382</td>\n",
       "      <td>0.939175</td>\n",
       "      <td>0.937002</td>\n",
       "      <td>0.937726</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.645909</td>\n",
       "      <td>0.737147</td>\n",
       "      <td>0.857350</td>\n",
       "      <td>0.925416</td>\n",
       "      <td>0.913106</td>\n",
       "      <td>0.893555</td>\n",
       "      <td>0.887038</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.01       0.1       1.0      10.0     100.0    1000.0   10000.0  \\\n",
       "rbf     0.716149  0.909006  0.944720  0.965528  0.985404  0.992236  0.995342   \n",
       "linear  0.918012  0.928571  0.930435  0.931366  0.934783  0.932609  0.932919   \n",
       "poly    0.616460  0.725155  0.845963  0.949689  0.970497  0.987267  0.992236   \n",
       "rbf     0.727009  0.914555  0.937002  0.938450  0.927589  0.918899  0.905141   \n",
       "linear  0.927589  0.930485  0.929761  0.933382  0.939175  0.937002  0.937726   \n",
       "poly    0.645909  0.737147  0.857350  0.925416  0.913106  0.893555  0.887038   \n",
       "\n",
       "                  type  \n",
       "rbf     Train Accuracy  \n",
       "linear  Train Accuracy  \n",
       "poly    Train Accuracy  \n",
       "rbf      Test Accuracy  \n",
       "linear   Test Accuracy  \n",
       "poly     Test Accuracy  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_only_standarized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec64ce",
   "metadata": {},
   "source": [
    "## Now lets normalize after deleting the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a237d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_2 = df[\"target\"] #just need the target column for Y\n",
    "\n",
    "#three last variables\n",
    "X_2 = df.drop([\"target\", \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\"], axis=1) \n",
    "\n",
    "\n",
    "X_train_2, X_test_2, Y_train_2, Y_test_2 = train_test_split(X_2, Y_2, test_size = 0.3) #test size 0.2 is for the 80-20 split \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_2 = scaler.fit_transform(X_train_2)\n",
    "X_test_2 = scaler.fit_transform(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fcee11a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with C: 0.01, kernel: rbf\n",
      "train acc: 0.7270186335403727\n",
      "test acc: 0.7023895727733527\n",
      "-----------------------------\n",
      "model with C: 0.01, kernel: linear\n",
      "train acc: 0.9118012422360249\n",
      "test acc: 0.9174511223750905\n",
      "-----------------------------\n",
      "model with C: 0.01, kernel: poly\n",
      "train acc: 0.6251552795031056\n",
      "test acc: 0.6154960173787111\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: rbf\n",
      "train acc: 0.9142857142857143\n",
      "test acc: 0.9138305575669804\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: linear\n",
      "train acc: 0.9229813664596274\n",
      "test acc: 0.9174511223750905\n",
      "-----------------------------\n",
      "model with C: 0.1, kernel: poly\n",
      "train acc: 0.7285714285714285\n",
      "test acc: 0.7146994931209268\n",
      "-----------------------------\n",
      "model with C: 1, kernel: rbf\n",
      "train acc: 0.9440993788819876\n",
      "test acc: 0.9348298334540188\n",
      "-----------------------------\n",
      "model with C: 1, kernel: linear\n",
      "train acc: 0.9263975155279504\n",
      "test acc: 0.9188993482983345\n",
      "-----------------------------\n",
      "model with C: 1, kernel: poly\n",
      "train acc: 0.8593167701863355\n",
      "test acc: 0.8305575669804489\n",
      "-----------------------------\n",
      "model with C: 10, kernel: rbf\n",
      "train acc: 0.9639751552795031\n",
      "test acc: 0.9319333816075308\n",
      "-----------------------------\n",
      "model with C: 10, kernel: linear\n",
      "train acc: 0.9282608695652174\n",
      "test acc: 0.9217958001448225\n",
      "-----------------------------\n",
      "model with C: 10, kernel: poly\n",
      "train acc: 0.9465838509316771\n",
      "test acc: 0.9123823316437364\n",
      "-----------------------------\n",
      "model with C: 100, kernel: rbf\n",
      "train acc: 0.984472049689441\n",
      "test acc: 0.9297610427226647\n",
      "-----------------------------\n",
      "model with C: 100, kernel: linear\n",
      "train acc: 0.9288819875776397\n",
      "test acc: 0.9225199131064447\n",
      "-----------------------------\n",
      "model with C: 100, kernel: poly\n",
      "train acc: 0.9695652173913043\n",
      "test acc: 0.9087617668356264\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: rbf\n",
      "train acc: 0.9922360248447205\n",
      "test acc: 0.9116582186821144\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: linear\n",
      "train acc: 0.9295031055900621\n",
      "test acc: 0.9254163649529327\n",
      "-----------------------------\n",
      "model with C: 1000, kernel: poly\n",
      "train acc: 0.9841614906832298\n",
      "test acc: 0.8957277335264301\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: rbf\n",
      "train acc: 0.9953416149068323\n",
      "test acc: 0.8957277335264301\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: linear\n",
      "train acc: 0.9288819875776397\n",
      "test acc: 0.9283128167994207\n",
      "-----------------------------\n",
      "model with C: 10000, kernel: poly\n",
      "train acc: 0.9900621118012423\n",
      "test acc: 0.8769007965242578\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#different kernels we have to apply\n",
    "C = [.01, .1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "#list of kernels\n",
    "kernels = ['rbf','linear', 'poly']\n",
    "\n",
    "#train accuracy with diff kernels\n",
    "linear_train_accuracy_2 = []\n",
    "poly_train_accuracy_2 = []\n",
    "rbf_train_accuracy_2 = []\n",
    "\n",
    "#test accuracy with diff kernels\n",
    "linear_test_accuracy_2 = []\n",
    "poly_test_accuracy_2 = []\n",
    "rbf_test_accuracy_2 = []\n",
    "\n",
    "\n",
    "for c in C:\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        \n",
    "        #first, lets fit the model with the determine C and Kernel\n",
    "        #if kernel is poly, then it needs the degree 2, otherwise it is ignored for other kernels\n",
    "        model = SVC(C=c, kernel=kernel, degree = 2)\n",
    "        model.fit(X_train_2, Y_train_2)\n",
    "        \n",
    "        #we get our predictions\n",
    "        y_train_pred_2 = model.predict(X_train_2) \n",
    "        y_test_pred_2 = model.predict(X_test_2)\n",
    "        \n",
    "        #we obtain accuracy between predictions and data (from test and train Y)\n",
    "        train_accuracy_2 = accuracy_score(Y_train_2, y_train_pred_2) \n",
    "        test_accuracy_2 = accuracy_score(Y_test_2, y_test_pred_2)\n",
    "        \n",
    "        #now we qualify them\n",
    "        if kernel == 'rbf':\n",
    "            rbf_train_accuracy_2.append(train_accuracy_2)\n",
    "            rbf_test_accuracy_2.append(test_accuracy_2)\n",
    "            \n",
    "        elif kernel == 'linear':\n",
    "            linear_train_accuracy_2.append(train_accuracy_2)\n",
    "            linear_test_accuracy_2.append(test_accuracy_2)\n",
    "            \n",
    "        else:\n",
    "            poly_train_accuracy_2.append(train_accuracy_2)\n",
    "            poly_test_accuracy_2.append(test_accuracy_2)\n",
    "            \n",
    "            #now we display our results\n",
    "        print(f\"model with C: {c}, kernel: {kernel}\")\n",
    "        print(\"train acc:\", train_accuracy_2)\n",
    "        print(\"test acc:\", test_accuracy_2)\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ea60d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = pd.DataFrame([rbf_train_accuracy_2, linear_train_accuracy_2, poly_train_accuracy_2], columns=C, index=kernels)\n",
    "df_test_2 = pd.DataFrame([rbf_test_accuracy_2, linear_test_accuracy_2, poly_test_accuracy_2], columns=C, index=kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2516e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2['type'] = 'Train Accuracy'\n",
    "df_test_2['type'] = 'Test Accuracy'\n",
    "\n",
    "all_dfs_2 = [df_train_2, df_test_2]\n",
    "\n",
    "# Give all df's common column names\n",
    "\n",
    "model_deleted_standarized = pd.concat(all_dfs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "49e4d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.963975</td>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.911801</td>\n",
       "      <td>0.922981</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.928261</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.625155</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.859317</td>\n",
       "      <td>0.946584</td>\n",
       "      <td>0.969565</td>\n",
       "      <td>0.984161</td>\n",
       "      <td>0.990062</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.702390</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>0.934830</td>\n",
       "      <td>0.931933</td>\n",
       "      <td>0.929761</td>\n",
       "      <td>0.911658</td>\n",
       "      <td>0.895728</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.917451</td>\n",
       "      <td>0.917451</td>\n",
       "      <td>0.918899</td>\n",
       "      <td>0.921796</td>\n",
       "      <td>0.922520</td>\n",
       "      <td>0.925416</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.615496</td>\n",
       "      <td>0.714699</td>\n",
       "      <td>0.830558</td>\n",
       "      <td>0.912382</td>\n",
       "      <td>0.908762</td>\n",
       "      <td>0.895728</td>\n",
       "      <td>0.876901</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.01       0.1       1.0      10.0     100.0    1000.0   10000.0  \\\n",
       "rbf     0.727019  0.914286  0.944099  0.963975  0.984472  0.992236  0.995342   \n",
       "linear  0.911801  0.922981  0.926398  0.928261  0.928882  0.929503  0.928882   \n",
       "poly    0.625155  0.728571  0.859317  0.946584  0.969565  0.984161  0.990062   \n",
       "rbf     0.702390  0.913831  0.934830  0.931933  0.929761  0.911658  0.895728   \n",
       "linear  0.917451  0.917451  0.918899  0.921796  0.922520  0.925416  0.928313   \n",
       "poly    0.615496  0.714699  0.830558  0.912382  0.908762  0.895728  0.876901   \n",
       "\n",
       "                  type  \n",
       "rbf     Train Accuracy  \n",
       "linear  Train Accuracy  \n",
       "poly    Train Accuracy  \n",
       "rbf      Test Accuracy  \n",
       "linear   Test Accuracy  \n",
       "poly     Test Accuracy  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deleted_standarized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdea2b",
   "metadata": {},
   "source": [
    "## Now lets put them in format (tables together) and compare them\n",
    "\n",
    "Here, we care mostly about the Test Accuracy results of each table to measure robustness, so the last three rows are the ones that matter the most for our analysis.\n",
    "\n",
    "For our first model (deleting the last three variables) we have:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a1d58970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.701553</td>\n",
       "      <td>0.912112</td>\n",
       "      <td>0.946894</td>\n",
       "      <td>0.965839</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.996273</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.912733</td>\n",
       "      <td>0.924534</td>\n",
       "      <td>0.926708</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.931056</td>\n",
       "      <td>0.931988</td>\n",
       "      <td>0.932298</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.629193</td>\n",
       "      <td>0.724224</td>\n",
       "      <td>0.852795</td>\n",
       "      <td>0.951242</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>0.991925</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.682114</td>\n",
       "      <td>0.902969</td>\n",
       "      <td>0.918175</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.921072</td>\n",
       "      <td>0.901521</td>\n",
       "      <td>0.881245</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.905865</td>\n",
       "      <td>0.911658</td>\n",
       "      <td>0.911658</td>\n",
       "      <td>0.918175</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.608979</td>\n",
       "      <td>0.724113</td>\n",
       "      <td>0.843592</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>0.885590</td>\n",
       "      <td>0.876901</td>\n",
       "      <td>0.873280</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.01       0.1       1.0      10.0     100.0    1000.0   10000.0  \\\n",
       "rbf     0.701553  0.912112  0.946894  0.965839  0.986957  0.993789  0.996273   \n",
       "linear  0.912733  0.924534  0.926708  0.929503  0.931056  0.931988  0.932298   \n",
       "poly    0.629193  0.724224  0.852795  0.951242  0.972671  0.986957  0.991925   \n",
       "rbf     0.682114  0.902969  0.918175  0.916003  0.921072  0.901521  0.881245   \n",
       "linear  0.905865  0.911658  0.911658  0.918175  0.916003  0.913831  0.913831   \n",
       "poly    0.608979  0.724113  0.843592  0.913831  0.885590  0.876901  0.873280   \n",
       "\n",
       "                  type  \n",
       "rbf     Train Accuracy  \n",
       "linear  Train Accuracy  \n",
       "poly    Train Accuracy  \n",
       "rbf      Test Accuracy  \n",
       "linear   Test Accuracy  \n",
       "poly     Test Accuracy  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_without_last3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31beb52a",
   "metadata": {},
   "source": [
    "Here, the best model is found in Kernel rbf, and C = 100. The performance we are referring to is 0.921072 for Test Accuracy. The linear model is the second best, while the Quadratic model performs not that well. It is also interesting to know that the best number for C to be is around 10 and a 100 for all of them, and after that their accuracy tends to go down (same as when c is very small)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6776c093",
   "metadata": {},
   "source": [
    "Our second model where we do not skip any variables and just standarize it all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "63876833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.716149</td>\n",
       "      <td>0.909006</td>\n",
       "      <td>0.944720</td>\n",
       "      <td>0.965528</td>\n",
       "      <td>0.985404</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.918012</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.931366</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.932609</td>\n",
       "      <td>0.932919</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.616460</td>\n",
       "      <td>0.725155</td>\n",
       "      <td>0.845963</td>\n",
       "      <td>0.949689</td>\n",
       "      <td>0.970497</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.727009</td>\n",
       "      <td>0.914555</td>\n",
       "      <td>0.937002</td>\n",
       "      <td>0.938450</td>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.918899</td>\n",
       "      <td>0.905141</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.930485</td>\n",
       "      <td>0.929761</td>\n",
       "      <td>0.933382</td>\n",
       "      <td>0.939175</td>\n",
       "      <td>0.937002</td>\n",
       "      <td>0.937726</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.645909</td>\n",
       "      <td>0.737147</td>\n",
       "      <td>0.857350</td>\n",
       "      <td>0.925416</td>\n",
       "      <td>0.913106</td>\n",
       "      <td>0.893555</td>\n",
       "      <td>0.887038</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.01       0.1       1.0      10.0     100.0    1000.0   10000.0  \\\n",
       "rbf     0.716149  0.909006  0.944720  0.965528  0.985404  0.992236  0.995342   \n",
       "linear  0.918012  0.928571  0.930435  0.931366  0.934783  0.932609  0.932919   \n",
       "poly    0.616460  0.725155  0.845963  0.949689  0.970497  0.987267  0.992236   \n",
       "rbf     0.727009  0.914555  0.937002  0.938450  0.927589  0.918899  0.905141   \n",
       "linear  0.927589  0.930485  0.929761  0.933382  0.939175  0.937002  0.937726   \n",
       "poly    0.645909  0.737147  0.857350  0.925416  0.913106  0.893555  0.887038   \n",
       "\n",
       "                  type  \n",
       "rbf     Train Accuracy  \n",
       "linear  Train Accuracy  \n",
       "poly    Train Accuracy  \n",
       "rbf      Test Accuracy  \n",
       "linear   Test Accuracy  \n",
       "poly     Test Accuracy  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_only_standarized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6ffb0",
   "metadata": {},
   "source": [
    "Here, the best model is found in Kernel rbf, and C = 10. The performance we are referring to is 0.938450 for Test Accuracy. The linear model is the second best, while the Quadratic model still performs not that well. Here, as C goes up, our linear accuracy improves, to levels that can match the maximun found with Kernel rbf. However, the lower the C, the better, so we will also remain with rbf for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849241f",
   "metadata": {},
   "source": [
    "And then the model where we deleted the three variables, and then standarized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "41208791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>10000.0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.963975</td>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.911801</td>\n",
       "      <td>0.922981</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.928261</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.929503</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.625155</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.859317</td>\n",
       "      <td>0.946584</td>\n",
       "      <td>0.969565</td>\n",
       "      <td>0.984161</td>\n",
       "      <td>0.990062</td>\n",
       "      <td>Train Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf</th>\n",
       "      <td>0.702390</td>\n",
       "      <td>0.913831</td>\n",
       "      <td>0.934830</td>\n",
       "      <td>0.931933</td>\n",
       "      <td>0.929761</td>\n",
       "      <td>0.911658</td>\n",
       "      <td>0.895728</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.917451</td>\n",
       "      <td>0.917451</td>\n",
       "      <td>0.918899</td>\n",
       "      <td>0.921796</td>\n",
       "      <td>0.922520</td>\n",
       "      <td>0.925416</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poly</th>\n",
       "      <td>0.615496</td>\n",
       "      <td>0.714699</td>\n",
       "      <td>0.830558</td>\n",
       "      <td>0.912382</td>\n",
       "      <td>0.908762</td>\n",
       "      <td>0.895728</td>\n",
       "      <td>0.876901</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.01       0.1       1.0      10.0     100.0    1000.0   10000.0  \\\n",
       "rbf     0.727019  0.914286  0.944099  0.963975  0.984472  0.992236  0.995342   \n",
       "linear  0.911801  0.922981  0.926398  0.928261  0.928882  0.929503  0.928882   \n",
       "poly    0.625155  0.728571  0.859317  0.946584  0.969565  0.984161  0.990062   \n",
       "rbf     0.702390  0.913831  0.934830  0.931933  0.929761  0.911658  0.895728   \n",
       "linear  0.917451  0.917451  0.918899  0.921796  0.922520  0.925416  0.928313   \n",
       "poly    0.615496  0.714699  0.830558  0.912382  0.908762  0.895728  0.876901   \n",
       "\n",
       "                  type  \n",
       "rbf     Train Accuracy  \n",
       "linear  Train Accuracy  \n",
       "poly    Train Accuracy  \n",
       "rbf      Test Accuracy  \n",
       "linear   Test Accuracy  \n",
       "poly     Test Accuracy  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deleted_standarized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744add2",
   "metadata": {},
   "source": [
    "Same story as we have seen before, the highest accuracy is found on the Kernel rbf with 0.934830 test accuracy, on C = 1 though, substantially lower than our other models. The linear model is still getting very close to rbf performance, but its score increases as C increases as well, consistently with our second model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21619c36",
   "metadata": {},
   "source": [
    "## Then, we can conclude that Kernel RBF, with C = 10, on a normalized dataset without deleting any columns is the best model we can obtain in order to predict if an email is spam or not, with a test accuracy of  0.938450. \n",
    "\n",
    "A very close result is the RBF with C = 1 on the model that was normalized and the last three columns where deleted, with test accuracy of 0.934830, which is a fair tradeoff to not have a C = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85227968",
   "metadata": {},
   "source": [
    "## Provide an intuition for the results observed for different kernels and different C's\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "57363076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df[df.target == 1]\n",
    "df_not_spam = df[df.target != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "52b5f9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e888a1f8e0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df_spam['char_freq_$'], df_spam ['char_freq_!'], color = 'red', marker = '+')\n",
    "plt.scatter(df_not_spam['char_freq_$'], df_not_spam ['char_freq_!'], color = 'green', marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fbc72",
   "metadata": {},
   "source": [
    "Trying to plot all the combinations would be a very hard job, and in most of the cases, since there's no really a weight on the importance of each variable in predicting, its hard to say what is the adequate Kernel for a multidimensional case like this. An spam email has a proper amount of characteristics that is remarked by a hyperplane on all the dimensions of the dataset. Then, it would be best to see the shape of this hyperplane by testing different kernels, and that's what we did.\n",
    "\n",
    "Interesting enough, it seems like spam emails have more outliers in certain characteristics than normal emails, and this might play a role on why the Quadratic kernel wouldnt perform as well as the others.\n",
    "\n",
    "Moreover, as we saw, the linear model was very close to the results of the rbf kernel, suggesting that there's a linear hyperplane that could classificate this data pretty efficiently. However, we mostly saw strong results on linear kernels when c was higher and higher, approaching a 1000, and that might just be too much slack in some cases. Let's note that C is a regularization parameter that controls the trade off between the achieving a low training error and a low testing error that is the ability to generalize your classifier to unseen data (a synonym to what we referred as soft-margin in our class). Then, as C goes higher, we run more into the risk of overfitting our data. Then, we will say that the rbf kernel is the best one on explaning the shape of the hyperplane without having to overfit too much.\n",
    "\n",
    "In conclusion, because of the nature of the characteristics of a spam email, it was predictable that the linear kernel (as in more other cases) was not going to be sufficient in terms of test accuracy, and it only was if C was high. Regarding the Quadratic kernel, with out plotting we can see that it won't follow a relationship like that. And finally, because of the adaptiveness of the rbf kernel, we are able to get strong accuracy results without having to add too much slack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
